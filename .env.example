# AI Pick Daily - Environment Variables

# LLM Configuration
LLM_PROVIDER=gemini                          # gemini | claude
SCORING_MODEL=gemini-2.5-flash-lite          # Model for daily scoring (cost-efficient)
ANALYSIS_MODEL=gemini-3-flash-preview        # Model for judgment/analysis (Layer 2)
REFLECTION_MODEL=gemini-3-pro-preview        # Model for reflection (Layer 3)
DEEP_RESEARCH_MODEL=gemini-3-pro-preview     # Model for deep research (Layer 4)

# Gemini API
GEMINI_API_KEY=your_gemini_api_key_here

# Claude API (for future migration)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Finnhub API
FINNHUB_API_KEY=your_finnhub_api_key_here

# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

# OpenAI-Compatible Endpoint (vLLM, Ollama, Together AI, etc.)
OPENAI_BASE_URL=http://localhost:8000/v1
OPENAI_API_KEY=no-key
OPENAI_MODEL=

# Shadow Model Comparison via OpenRouter
ENABLE_SHADOW_JUDGMENT=false
OPENROUTER_API_KEY=
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# Comma-separated OpenRouter model IDs
SHADOW_MODELS=meta-llama/llama-3.3-70b-instruct,anthropic/claude-sonnet-4,google/gemini-2.5-flash

# Optional: Debug mode
DEBUG=false
